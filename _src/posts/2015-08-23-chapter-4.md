    Title: Chapter 4: Minding Your Turtles
    Date: 2015-08-23T01:10:00
    Tags: Persistence, Transience, Turtles, DRAFT


Ngnghm examined how manual persistence was managed underneath Human computer systems,
and contrasted with how Houyhnhnms automated its implementation.
This led him to more general remarks about the compared architectures of
Human computer systems and Houyhnhnm computing systems.

<!-- more -->

### Stacked up against Quality

Ngnghm wanted to know how Humans dealt with [manual persistence](/blog/2015/08/03/chapter-2-save-our-souls/).
He found that we were using an large quantity of mutually incompatible "libraries"
in each of many loose categories that each implement some aspect of persistence:
"I/O", "file formats", "serialization", "marshalling", "markup languages", "XML schemas", "protocols",
"interchange formats", "memory layout", "database schema", "database servers",
"query languages", "object relational mapping", "object request brokers", "foreign function interface",
and many "wrappers", "adapters" and "glue layers" to make them work together.
Indeed, some old IBM study had estimated that 30% of all application code written
was related to the basic functions of saving data and restoring it
— and at least my experience corroborated the ballpark of this estimate.
Houyhnhnms, like Dijkstra, regard this as a huge cost:
([if we wish to count lines of code, we should not regard them as "lines produced" but
as "lines spent": the current conventional wisdom is so foolish as to book that count on
the wrong side of the ledger.](https://www.cs.utexas.edu/~EWD/transcriptions/EWD10xx/EWD1036.html))

Unhappily, that huge cost also comes with limited benefits, because
programs can only manipulate an object if they get the entire large assemblage of libraries just right,
and thus two objects built on top of incompatible _software stacks_ cannot interoperate.
Costly adapters, that can be written to bridge between the two stacks,
but this not only requires extra copying and management by programmers,
this also loses any atomicity properties of transactions between the two object systems
— and isn't accessible casual users, who pain to manage their data.

Moreover, the above estimate did not include the error handling strategies when the above failed,
whereas the complexity of these baroque assemblages incur enormous security risks.
Indeed, a lot of "layers" in these software "stacks" are written in unsafe low-level languages
for reasons of alleged "performance" or "compatibility",
whereas another (overlapping) lot of such "layers" include some
complex [manual parsing](https://www.usenix.org/system/files/login/articles/login_aug15_02_bratus.pdf) of arguments
that are as many points where attackers may inject unwanted behavior;
these many layers further interact in a way that makes it nearly impossible to assess
the overall semantics of the system, much less its security properties.

This architecture in software stacks is thus detrimental not only to persistence,
but also to robustness, to security, to performance, to upgradability, to maintainability, etc., etc.
— all the qualities that managers of Human computer development projects often demote as being "non-functional",
because their development processes are so deeply dysfunctional,
at least from the Houyhnhnm point of view:
by neglecting as an afterthought aspects of software development
that are not directly visible in a quick test of a software artefact,
these processes ensure that they cannot be addressed properly.
By contrast, Houyhnhnm computing systems consider the software development and use processes as primary,
not the artefacts, and thus consider these aspects as primary properties of the overall system,
that are important to address as part of the architecture of the softwaring process.


### Meta-level modularity

Houyhnhnms don't have any library to manage persistence;
instead, Houyhnhnms have a number of libraries to manage transience.
Indeed, persistence is a system-wide protocol, universally provided using generic strategies.
But you may want to extend this protocol to more efficiently support
some data type (say, some domain-specific compression),
some consensus protocol (say, some variant of the PAXOS algorithm),
some reconciliation process (say, some new CRDT),
or some resource ownership discipline (say, some variant of linear logic).
That's when you specify a new implementation strategy for common system protocols,
usually as a modular incremental variant of openly-accessible existing strategies.

Note that strategies are not mere libraries;
they are meta-level programs that implement regular programs,
and may include runtime libraries, but also compile-time libraries.
Thus, different code may generated for the "same" program,
depending on what strategies are in the _domain_ in which it is run:
marking of modified objects, individually, in "cards" or in "pages"
for garbage collection or persistence;
maintaining (unique) (local or remote) reference counts or sets;
blitting directly to video memory or issuing requests to some server;
checking some kind of types statically or dynamically;
etc.
where the program doesn't otherwise have to care about persistence...

Thus, Houyhnhnm systems importantly have a notion of a programming system
that is abstract from any specific implementation strategy,
so that a same program (which includes not only source language, but also running state)
may be run with different strategies —
and indeed with strategies that vary during its execution.
Thus, it is always possible for objects to interoperate;

migrate them to a common domain.

AOP

Whereas Houyhnhnm computing systems work at the level of abstract data types,
so messaging happens with robust system-provided parsers.

This generalizes this remark made by Paul Graham that on Lisp, as compared to other languages,
"You can get fast programs, but you have to work for them.
In this respect, using Lisp is like living in a rich country instead of a poor one:
it may seem unfortunate that one has to work so as to stay thin, but surely this is better
than working to stay alive, and being thin as a matter of course."

XXX
that to cooperate on the same data structures,
programs have to reuse the very same big assemblage of such libraries,
that will define not just the semantics of said data structures,
but the entire semantics of all the underlying computing domains down to the bare metal.

In each of these categories, the offering consists in plenty of software projects,
all of them mutually incompatible and somewhat fragile.


Write in high-level style.
As a trivial example, a mathematical definition of the Fibonacci function
might be annotated with a compile-time assertion that the linear recursion recognizer will kick in,
at which point the system guarantees that the function will be computed
in constant time for small  polylog time.




### Building up vs building down

Ngnghm hadn’t noticed at first this essential transience of all data in Human computer systems.
Any and all of Human data may disappear at any time without notice.
To prevent or mitigate this loss, Humans have to explicitly take extraordinary steps
to save all kinds of data, regularly, with rigorous discipline.
Each bit of data requires its own special steps to save and sometimes much harder to restore
— if by a combination of bad luck yet good preparation some Humans lost their data
but possessed some form of a backup.
And that there exists no imaginable mechanism to restore data in a coherent way
across several software or hardware components,
making the restoration of a simple terminal user’s computer a hard task,
and that of an actual live service a heroic feat.

Moreover, all data was bound to disappear eventually.
Not only hardware, but also software, was often expected to be used until it failed,
with no regular plan to transfer data to a replacement system until it had at least started to fail.
Human applications are written in an extremely fragile way,
where persistence and correctness are considered "non-functional" requirements
and are dealt with as an afterthought — and are thus addressed in a _dys_functional way.

Therefore, it is expected that applications will crash,
have a race condition with other applications, experience plain old bugs,
or be subject to vulnerabilities,
at which point users will irremediably lose configuration or session data,
documents written or data entered.
(Interestingly, while it is all too easy for data you care about to be deleted,
yet it is very hard to make sure that some data you want forgotten is ever completely deleted.)



Delivering software as components, not applications (Human closest: browser plugins)

Humans can only build but _up_. Houyhnhnms can build both up _and_ down.

Always jump into the "top" (bottom) universe and rebase reality.

Houyhnhnms implement _strategies_ that can then be applied.

Like [Urbit _jets_](http://moronlab.blogspot.fr/2010/01/urbit-functional-programming-from.html),
except now built into the system, but selectable by users.
Urbit is still a "build upwards only" system.

Inconsistent strategies can cause inconsistent behavior,
but only within the narrow scope that adopted them.

Towers and Stacks


Humans have large and complex libraries to fake persistence on top of essential transience at every level.
Houyhnhnms consider persistence a basic system property at every level,
and have relatively simple libraries to escape into transience
where performance or fine-grained semantics (or system bootstrap) calls for it.
Humans have many devices that they connect into networks, where bits are copied.
Houyhnhnms have a single system that they subdivide into domains,
between which data is distributed (more like [Urbit](http://moronlab.blogspot.com/2010/01/urbit-functional-programming-from.html)).

Not only does that make Houyhnhnm systems much simpler,
it also guarantees forever interoperability of every single piece data with any future system,
at whichever level of abstraction that data was defined.
If you want your data to remain relevant to your future self, or to be usable by other people, etc.,
you still need to wisely choose suitable algebraic data types,
to organize software into components with clean interfaces,
to pick appropriate policies that lead to suitably performant implementations,
to rely on suitable libraries.


### Adding turtles below

Human computer systems start from a given base, and build up.
Slightly more advanced Human computer systems, using macros,
can at compile time lift the system up and add a number of layers below.
(For an extreme case, see Common Lisp in Common Lisp implementations
used to add first-class continuations, sometimes also serializable,
so as to enable backtracking and/or continuation-based web programming.)
Some interactive development systems also instrument the virtual machine
so as to lift execution into something that allows for debugging.
But even then, once the program is built, once the runtime has been chosen,
once the program has started running,
the system remains forever grounded on top of the chosen basis.
Houyhnhnm computer systems, by contrast,
can dynamically add new layers below a running program.
Add a turtle beneath the existing stack of turtles,
and lifting the entire stack of turtles, while the system is running.
