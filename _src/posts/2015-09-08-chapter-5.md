    Title: Chapter 5: They live!
    Date: 2015-09-08T12:54:23
    Tags: DRAFT, Live programming, Upgrade, Types

[Ngnghm](http://ngnghm.github.io/blog/2015/08/02/chapter-1-the-way-houyhnhnms-compute/)
decided that while stranded among us, he would conduct
an ethnographical study of Human computer systems,
and took to heart to examining my programming habits.
In return, I was more and more curious of how Houyhnhnm systems worked, or failed to work.
That's when, trying to imagine what the Houyhnhnm computing systems might keel over,
with their making everything persistent, I had this a-ha moment:
surely, they must have extreme trouble with schema upgrade,
and their programmers must spend their time in hell trying to reconcile modifications
in what amounts to an unrestricted distributed database, that anyone can modify at any time.
Ngnghm wasn't sure what I was talking about that could be a major issue,
and so interrogated me as to the Human practices with respect to handling change in persistent data
— and found that many of the issues stemmed from limitations with how Human approached the issue,
rather than being intrinsic with the problem of ensuring persistence of data.


<!-- more -->

### The Best Laid Schemas of Houyhnhnms and Men

I challenged Ngngnhm to explain to me how Houyhnhnm systems dealt with code and data upgrade, because
they were some of the hardest problems I had faced while working with Human computer systems.
Ngnghm wasn't sure what I meant, or if he did why it would be particularly difficult.
That surprised me, so I started by stating that any software that survives long enough
has to change its code as the software became obsolete, in a phenomenon humorously known as
[_bitrot_](http://www.jargon.net/jargonfile/b/bitrot.html):
as time goes by, the software becomes no good anymore,
as if it were being degraded by some kind of rot;
of course, and that's the joke, no external force can possibly cause
the bits that compose the software to change and degrade
— on the contrary, the problem is precisely that the software fails to change
when the world around does and requires the software to adapt so as to remain relevant.
Ngnghm told me that the analogy makes sense to Houyhnhnms but isn't as humorous:
it isn't the software, but the _relationship of the software with the world_, that rots;
the degradation thus applies not to the comput_er_ system, but to the comput_ing_ system,
as constituted not just by the computer, but also by the humans,
and by the larger context in which the computation happens.
To a Human focused on the software artefact, it may be a funny paradox;
but to a Houyhnhnm focused on the softwaring process, it's a painful truism.

I was intrigued, but I went on.
As a program evolves, the format in which it stores data, its _schema_,
will eventually be found wanting, as well designed as it might originally have been
for its purpose initial purpose.
New _data types_, new _file formats_, new _database schemas_, will be needed,
as the old one becomes insufficient and inadapted
to newly required kinds of computations.
Now, the correspondances between old and new data is often non-trivial,
and upgrading data from the old format to the new format is hard;
what more, upgrading _all_ the data, consistently,
without any race condition between old and new data processors, was even harder.
and if the upgrade has to happen without any down time from the system as it keeps processing data,
the problem becomes a feat for a virtuoso.
Finally, bugs in such an upgrade process were both
dall too easy to introduce and all too hard to recover from,Therefore, Human computer systems shunned these upgrades as much as possible, cc1
and some companies paid people full time just to manage the writing and/or smooth running
of upgrade scripts that kept their data up to date,
and to keep up the expensive database servers capable of doing it reliably.

However, humans were lucky enough
to be able to avoid these difficult data upgrades altogether in most cases,
precisely because Humans were not persisting data but throwing it away, so it didn't need to be upgraded.
When they really had to deal with the hard case,
the best tool Human computer systems possessed was the CLOS protocol for
[`update-instance-for-redefined-class`](http://malisper.me/2015/07/22/debugging-lisp-part-3-redefining-classes/)
whereby users define transformations and the system manages schema upgrade on a per-object basis;
but even for the happy few able to use CLOS
(for which no equivalent existed in any other Human computer system),
the consistency between the many versions and the upgrade functions
still has to be assessed and enforced manually by the sentient programmer, at a great cost;
more primitive tools like [protocol buffers](https://github.com/google/protobuf)
or its successor [Cap'n'Proto](https://capnproto.org/)
were also available, being both less expressive in terms of types
and leaving much more to the programmers in terms of managing upgrades,
but at least providing a framework for data to survive and be upgraded
beyond the short life of a program that by necessity can only handle one version of the schema.
And yet most people just did it the hard way, either with completely disjoint old and new schemas,
duplicated code, and big ad hoc functions to translate between them,
or with ad hoc sharing of code and data between the schemas,
a complexity that increases with each new version,
and plenty of corner cases that are never considered much less tested.

Surely, by persisting everything all the time, Houyhnhnm computing systems
were forced to deal with this hard issue all the time,
which of necessity must have made all programming difficult and tedious.
Yet Ngnghm claimed that he didn't know data upgrade to be particularly tedious on Houyhnhnm systems.


### Afterthought or forethought

First, he said, the case that was easy in Human computer systems,
namely eschewing any upgrade and dropping the old data
was just as easy in Houyhnhnm computing systems:
just don't upgrade the data, and drop it, as you modify the code.
If you don't care about data, then by definition you don't care whatever
automation the system provides to upgrade it for you, and don't care to fix it;
if you know that for sure in advance, you can even tell the system,
so it won't bother saving the data, and you might get a nice speed up for it.
However, in the cases the data actually matters and you do care about it,
that's when you'll miss system support for data persistence,
and that's also when you'll miss system support for upgrading your data.

Moreover, even in this easy case, since Houyhnhnms,
[as you may remember](http://ngnghm.github.io/blog/2015/08/09/chapter-3-the-houyhnhnm-version-of-salvation/),
save code and data together,
you could simply fork the old data together
with the correct version of the code that knows how to create and manipulate it,
and keep using it while you work on a new version.
"Orphaned data", "version mismatch", "DLL hell", are issues that might sometimes delay upgrade,
and cause a lot of grief to Houyhnhnm programmers indeed,
but they never can prevent reusing current or old data
— computation itself is immortal, even if its relationship to the world can suffer.

Second, since the "canonical" representation of data is not low-level bytes, but high-level data types,
a whole lot of extrinsic complexity that Human computer systems have to deal with
can instead be automated away:
a trivial strategy is always available for upgrade (decompile and recompile),
and all the management of which object currently uses which underlying representation
can be done by the system and requires no sentient oversight.
The sentient programmers can then focus on the actual intrinsic issues of schema upgrade:
data transformations into semantically non-equivalent data types
— and even then, the system provides a framework that automates a lot.

Third, and more importantly, upgrade is inevitable indeed;
but the problem with Human computer systems is that since they
both focus on software as a finished artefact and define things at a low-level,
they drop all the data that matters about upgrade when it's readily available,
only to desperately try to reconstitute it the hard way after it's too late.
Upgrade automation is thus almost inexistent in Human computer systems,
because it comes as an afterthought.
By contrast, it comes naturally in Houyhnhnm computing systems,
because it is part and parcel of how they conceive software development.


### Change Comes from the Inside

To Humans, change happens _outside_ the computer system that is changed:
to change a program requires shutting down the processes (limited virtualized computer systems)
started with the program and starting new processes with the new program,
for a program is immutable once started.
As for changing a program's data types and having to preserve data,
that's an exceptional situation to be dealt with using exceptional tools,
as a catastrophic event happening every so many months or even years,
when releasing a new version of the program.

To Houyhnhnms, change happens _inside_ the computing system that changes,
because everything relevant is ipso facto inside the system, part of its ontology.
What more, to Houyhnhnms, change to programs is what programming verily is:
To program is to change programs, and to change programs is to program.
It's a tautological identity.
Inasmuch as types are part and parcel of a program, then
changing a program's data types is part and parcel of programming
and is supported by the system as a matter of course,
including upgrading any existing data to use the modified types.

To a Houyhnhnm, the idea that change could happen _outside_ the system is absurd on its face,
as is the notion that a programming language
could only be concerned with describing programs that never change.
Of course, change processes may or may not be automated — but as per the
[_Sacred Motto_ of the Guild of Houyhnhnm Programmers](http://ngnghm.github.io/blog/2015/08/03/chapter-2-save-our-souls/),
whatever parts of them _can_ be automated, _should_ be automated, _must_ be automated, _will_ be automated,
until eventually they _are_ automated.

Once again, Humans focus on _programs_ as finished entities with fixed semantics,
whereas Houyhnhnms think in terms of _systems_ made of ongoing interactions.
And once again, this
[fundamental difference in paradigm](http://www.dreamsongs.com/Files/Incommensurability.pdf)
implies fundamental differences in the most basic structures of computing systems,
including programming languages.


### Human languages that support upgrade

However, there are two notable exceptions amongst Human programming languages,
whereby the language does (to some degree) support changes to programs and data types
from _within_ the language: Common Lisp, and Erlang.

Common Lisp lets you redefine functions, classes, types, etc., in an existing, running _image_,
and immediately thereafter use the modified program.
There are however a lot of limitations and a lot of pain in doing so,
especially if the program has to be actively running while the modifications take place.
For instance, you may have to declare your functions `notinline` to ensure the latest version is always used,
or to `shadow` their symbol to ensure the version at time of definition is always used.
Before you redefine a class, you can define methods on `update-instance-for-redefined-class`,
to ensure that all data will be properly upgraded after the class redefinition;
this is somewhat low-level, there is no automated enforcement of consistency
between such methods and the types, and you better keep supporting older versions of the class,
just in case some instances still haven't been upgraded;
but it's there and it works.
The big problem with Common Lisp is that its model of side-effects to a single global world
doesn't play well with a modern distributed world,
where a complete system is made of many processes running on many machines,
or where you want to have multiple versions of the software running at the same time.
It hasn't been actively developed as a complete _system_ for three decades,
and what remnant support it has for this way of thinking is
a partial subset of whatever primitive solutions existed when it was standardized.
Yet that it supports code and data upgrade at all without resorting to magic from outside the language
makes it miles ahead of all known Human languages. Except Erlang.

Erlang's heritage and ambitions are very different from those of Lisp,
and in many ways it is much more primitive — but as an upside its primitives are better defined.
Through a reinvention decades later, Erlang embodies the Actor model of the early 1970s,
which is what the "Object Oriented" utterly failed to be despite its own hype:
a model where many _active_ entities (called "processes" in Erlang, rather than "objects")
communicate with each other by passing _messages_.
Processes can be distributed, and reliability is achieved by assuming that
individual processes will fail eventually, letting them fail, and restarting them,
whereas important data will have been stored and replicated in other processes.
Now, one thing where Erlang shines, far better than Lisp and far far better than anything else,
is in its support of live upgrade of code and data — a topic that it alone seems to take seriously.
When you upgrade code, it is always clearly defined which function calls will go to the old version,
and which function calls will go to the new version.
And the strict model in terms of processes and messages makes it possible to reason
about what state each process is in, how it will update its state,
and and how it will handle old or new messages.
All in all, Erlang feels like a low-level language,
but not a Human low-level language, that tries to track the underlying computer hardware for efficiency,
and more like a Houyhnhnm low-level language,
that tries to track the underlying computing model for correct reliable behavior;
what makes it less than a high-level language is that it isn't easy enough
to build higher abstractions on top of the provided abstraction level
(though it may still be better at it than many alleged "high-level" Human programming languages).

Therefore, there are some precedents in Human computing systems that
allude to what Houyhnhnm computing systems would be.
But they are quite undeveloped as to what would be required of a full-fledged Houyhnhnm computing system.


## Live Upgrade

So what do Houyhnhnm programming languages look like when it comes to supporting
Live Upgrade of code and data in a running program?

First, Houyhnhnm programming languages have a notion of atomic transaction for code and data upgrade,
so that you can _coherently_ upgrade a system from one version to another,
without having to wonder what happens if some code is running right in between
when two mutually dependent functions or types are being redefined.
Of course, while developing, Houyhnhnm programmers will want to experiment and explore
with upgrades of some part of the code or data only, that lack overall system coherence;
such exploratory modifications are doomed to fail, but that's alright,
because they are run in a virtual fork of the system.

Houyhnhnm type systems track how incoherent the system is, and guide the programmer
as to which part of the system follows the old types vs the new types.
At runtime, incoherent calls are intercepted before they may break,
and the debugger offers the programmer a chance to give a new function definition
before to enter (or re-enter) the function that fails —
(among Human programming languages, good Lisp implementations provide the latter,
whereas good statically typed languages provide a bit of the former).

Houyhnhnm systems, since they remember the history of type modifications,
require every a type modification to be accompanied by a well-typed upgrade function,
taking an object in the old type and returning an object in the new type.
Simple upgrade functions can be trivially expressed,
such as using default values for new fields, or erroring out.
The system also uses linear logic to ensure that when writing an upgrade operator,
you must _explicitly_ drop any data that you don't care about anymore,
so you can't lose information by mistake or omission
(old versions of the data will still persist by default,
as with all data in a Houyhnhnm system, but upgrade mistakes will make further fixes harder).
Because the same function doesn't necessarily apply to all data of a given type,
upgrade functions can be overridden at the granularity of individual variables,
and/or take some context as extra parameters.

The system also tracks the difference between some variable having been renamed
and some variable having been deleted and another added,
because they imply very different upgrade behavior.
Branching and merging are similarly supported.
These are very easy to track in an interactive development environment,
but hard to reconstitute, indeed impossible to reliably reconstitute,
just by looking at the code before and after the modifications,
when the language doesn't allow to explicitly express the difference.

Of course, Houyhnhnm systems allow you to edit the _effective history_
of coherent changes that applies to software releases,
as contrasted with the actual history of often incoherent changes through which the result was attained.
Thus, bugs introduced in the upgrade process can themselves be fixed.
Since Houyhnhnm computing systems accommodate for situations with many distributed agents
each with their own version of the code and data and their history,
the modifying, branching and merging of objects also apply to these histories of code and data changes.
Histories themselves constitute a monotonic algebra where it is always possible to merge histories;
but the system will also check the coherence of the results and reject incoherent transactions,
and/or require manual intervention by sentient programmers to fix the incoherences that it tracked.
Of course, this can get lead to arbitrarily complex situations
when merging histories in a distributed system;
but in practice, there is finitely many data that needs to be upgraded that people actually care about,
so there is a cap on how much complexity Houyhnhnm programmers need to deal with;
moreover, since Houyhnhnm computing systems, unlike Human computer systems, do track where all that data is,
Houyhnhnm programmers can be fairly confident that the upgrade of all relevant data is completed
and no further upgrade effort is required.

Now, none of this negates the interest of having a subset of the programming language
that allows to express and reason about immutable programs.
Immutability is indeed a very important property that Houyhnhnms programmers
appreciate as well as the more advanced Human programmers.
But when programs do mutate, and they do, by the very virtue of programming itself,
Houyhnhnm programmers much prefer being able to reason about these changes from within the system,
with all the automation that the system makes possible,
including automated refactoring, detection of incoherence, formal reasoning, etc.,
where instead Humans have to revert to completely informal reasoning on pen and paper,
having to indulge in expensive manual drudgery
which robs them from being able to focus on the difficult parts that really require their attention,
drowning the important details in an ocean of boring repetitive tasks.
Houyhnhnm programming languages thus allow to reason about immutable programs in a less-expressive setting
while simultaneously expressing meta-level programs in a more-expressive setting
that describe changes in the former from outside their universe,
but still within the automated part of the overall computing system.

In conclusion, as compared to Human computer systems,
Houyhnhnm computing systems handle all the easy cases of Live Upgrade,
and automatically ensure coherence for the hard cases,
where Humans instead rely on large bureaucracies of _database administrators_ and upgrade experts
to manually manage live upgrade of code and data
through excruciating slow and still error-prone unautomated processes.
And this, once again, is a natural consequence of the simple difference in _point of view_,
in "philosophy", between Human comput_er_ systems and Houyhnhnm comput_ing_ systems.
