    Title: Chapter 7: Applications
    Date: 2015-12-13T14:15:16
    Tags: DRAFT

My previous discussion with Ngnghm left me baffled:
I could somehow understand that
Houyhnhnm computing doesn't have the concept of an Operating System Kernel;
and I could vaguely guess how each of several aspects of a Human kernel
could have corresponding software patterns in a Houyhnhnm system,
at each of various levels of abstractions.
But while I could visualize each of these individual patterns,
it was less clear to me what the big picture was
when these smaller compile-time, link-time and runtime abstractions
were put together.
So I decided to approach the software architecture from the other end:
what do end-user applications look like in Houyhnhnm computing systems?


<!-- more -->

### Autistic Applications ###

By that time, Ngnghm was starting to get familiar with Human computer systems,
and the few end-user applications that he was using daily.
He explained that at least for self-contained end-user applications,
the situation was very similar, at least superficially:
games, interactive art, audiovisual performances, showroom displays, news and other writings, etc.,
things that are made to be explored by the user but not modified in any significant way.
The Houyhnhnms had a name for them that I translated as _autistic applications_:
applications that mostly didn't communicate much if at all with any other application.
These things looked pretty much the same in Houyhnhnm computing systems and Human computer systems:
You somehow get ahold of a program and its dependencies if any,
run it in a sandbox, and interact with it;
and it doesn't matter too much what the program does,
precisely because the information flow is essentially one way,
from the application to the user.

Still, there were a few subtle points
where even these autistic applications differ on Houyhnhnm computing systems
from what they look like on Human computer systems.
For instance, all applications inherit from the system its
[orthogonal persistence](/tags/Orthogonal-Persistence.html).
You can thus always interrupt the application and save and restore its state at any point in time,
except where explicitly not desired (e.g. in the middle of a transaction).
Then you could go back in time and replay
(and in the case of videos or music, go forward in time),
according to a protocol that is uniform across applications;
and not only was it no additional burden on application programmers,
it was something they couldn't get subtly wrong, and that users could thus casually rely upon.
There was never any loss of any session state, disappearing tabs or windows,
games where you couldn't save, etc.
There were no messages you had to enter twice because they were cleared between two loads,
or that reappeared because the clearing failed to be recorded.

Of course, applications that required interaction with a remote service
are always able to save and restore the client-side state from previous user interactions;
however that does not entail being able to save and restore any server-side state,
at least not without support from the server.
And while the system typically makes it easy for the server developers
to provide that support if they want,
they might not, for various reasons including cost and confidentiality.
For reasons of privacy, a user might conversely want to replay a previous session
without telling the remote server.
And for regression testing or debugging their applications, developers might want to replay
parts of the server side interactions without affecting the users.
All these are expressible in Houyhnhnm computing systems:
you can specify the scope and context in which you replay some computation,
within the resources that you control.


### Typical Applications ###

Most applications are not autistic:
they do involve exchanging data with other applications.
In other words, the information processes they partake in
may directly involve other automated programs;
they do not require a sentient being's brain (Human or Houyhnhnm)
as an intermediate between their processing and further automated processing.
(And there we see that even "autistic applications" are not "autistic processes".
An autistic application does not communicate with other automated programs,
but does interact with sentient users.
An "autistic process" that communicates with no other process whatsoever,
not even those in a sentient being's brain, can and will be wholly optimized away.)
And there, the situation is differs sharply between Human and Houyhnhnm systems.
Human computer systems tend to make communication between applications very difficult;
whereas this communication the heart of Houyhnhnm computing systems.

First, in Human computer systems, the only common abstractions are very low-level,
in terms of array of bytes.
Any higher-level objects have to be encoded into sequences of bytes,
shipped across costly runtime virtual process boundaries,
then decoded back into objects on the other side.
Applications thus have to agree on
complex, expensive, bug-prone yet inexpressive low-level communication protocols
that are big security liabilities.
A lot of this work can be completely automated using type-directed code-generation;
and the better Human systems do it to a point (see Protocol Buffers, piqi, etc.);
but the integration with types of actual programming languages remains generally lackluster.
What types can be used for generally shareable data remain very limited and inexpressive,
whereas whatever types they can use for manipulating data within a given program
remain generally oblivious of any sharing constraints, ownership rights, access restrictions, etc.
In Houyhnhnm computing systems, communication of objects is handled by the system
at the highest level of abstraction possible:
that of whichever types and checks are being used to define and validate these objects.
Low-level encoding and decoding can be eschewed altogether for linear objects
where both processes trust each other with respect to representation invariants;
it can sometimes be reduced to mere checking when the trust is incomplete;
and where encoding or checking is actually required, it is automatically extracted
based on type information available either at compile-time or at runtime.
The programming language types _are_ the communication types,
and if foreign languages need to communicate with each other,
it's a regular matter of FFI (Foreign Function Interface)
that you may want to solve anyway.

Second, Human computer systems have very poor algebras and interfaces
for users to combine processes.
For most users, sharing data between applications requires one of two things:
selecting and copying (or cutting) data from one application using a mouse,
then pasting it into another application;
or having the application save or export a file to a local disk,
then opening or importing that file in another application
(with "interesting" consequences when two applications try to modify it at the same time).
There is no way for regular users to name processes, much less connect them.
Developers can do it, but it's extremely complex;
and there's a large discontinuity between
the skills required to merely use the system,
and the skills required to do even the simplest things as you program the system.
Modern Human computer systems tend to allow for an intermediate layer between the two,
"scripting", with Unix shell pipes or the much more modern PowerShell on Windows;
this still remains quite complex to use, and limited in expressiveness:
scripting lowers the barrier to building applications out of simple utilities and libraries,
but ultimately doesn't allow users to connect the functionality of two different applications
without having to go through either copy-pasting or files.

Houyhnhnm computing systems are based on the premise of small modular entities
that each do one thing well;
and these entities can be combined inside a common framework
that does its best to reduce the discontinuity between using and programming.
A few pieces of Human software have historically followed a similar model:
Smalltalk workstations; Lisp Machines; Hypercard.
But perhaps the most successful surviving such framework to date is GNU Emacs:
it is largely written as a set of modules in a "scripting language" (Emacs Lisp);
entities defined in a module can be freely used in another one,
and data exchanged.
Its programming language is antiquated, and
its data structures are heavily biased towards text editing,
and yet it remains widely used and actively developed,
because in many ways it's still far ahead of any competition.

In a Houyhnhnm computing system, a new module may define new kinds of entities;
and as long as these entities implement common interfaces,
they can be used along all other such entities by previous modules.
For instance, a new picture compression format is automatically usable
by each and every function that uses pictures throughout the system;
a same extensible text editor with all the user's customizations (including replacing it wholesale)
can handle any kind of writable text in the system;
a same extensible picture editor can be used on all pictures anywhere on the system; etc.
Houyhnhnm programmers tend to not write standalone applications in non-autistic cases;
instead, they modularly extend the capabilities of their environment.

A new module may also define new interfaces, and how they apply to existing kinds of entities.
There of course a problem when two modules that don't know each other extend the system
by adding new kinds of entities and new kinds of interfaces, creating new cases that are not handled.
Houyhnhnm systems are not magic and can't generate handlers for those cases out of thin air;
a suitable generic fallback may have been provided with the new interface;
or lacking any, the system will fail and drop to its metasystem, that will handle the error.
In the end, it's still the job of some programmer to ensure the overall system works suitably.
These issues exist in Human and Houyhnhnm systems alike —
the only difference is that Human computer systems are so difficult to extend
that programmers seldom reach the point when they can confront these problems,
whereas Houyhnhnm computing system eliminate enough of the artificial problems in extending the system
that users are more often confronted with these extension-related issues.


### Implicit Naming ###

Communication with other processes can be explicit:
a process will specifically name another process or start a new process,
open a communication channel with it, and exchange data.
One reason why interprocess communication is so hard in Human computer systems,
is that these systems lack a good way to even name
the processes with which you'd like to communicate;
indeed, most processes lack any way to communicate with:
to communicate with another process, that process has to specifically
implement some server that listens on a known port,
or that registers on a common "data bus";
this is very complex, and may require tricky integration between several event loops,
or eschewing integration and dealing with hard concurrency issues;
this in addition to the low-level nature of the protocol discussed above
makes writing such a server an expensive proposition as well as a huge security risk
(and then we need to discuss mangement of access rights)
and so most programmers don't bother doing it.
The difficulty of locating one of a few processes available to communicate with
is of course compounded by the notorious instability and transience
of processes in Human computer systems;
you have to constantly name new processes and create new communication channels,
because these processes as well as your current process keep dying.
You can try to automate this communication,
but there is still a vast array of error cases that you will have to handle.

Houyhnhnm computing systems recognize that communication is something to handle
at the meta-level of the systems that are being made to communicate with each other.




Most of the time, though, communication is in some measure implicit:
a process will write data to its "standard output" and read from its "standard input",
which may be connected to a communication stream with another process, a terminal, or to a file;
data displayed to a terminal, or to the windows of applications that support it,
can be copied and thereafter pasted into another application;
files and communication streams are read by processes
that are largely independent from the processes that write to them.
In the end, each and every single instance of communication between distinct processes
involves _some_ implicit naming:
indeed, division of labor in programming is precisely
the ability to name a communication channel and
not have to worry too much about what's on the other side
except for its following the proper communication protocol.

In the rare cases that you do know exactly what's on the other side,
it's not inter-process communication, it's a (static) function call.
And indeed, a good enough Houyhnhnm computing system implementation
will compile invocation of known services into function calls wherever appropriate;
there may be good reasons pertaining to division of labor and program maintenance
for the application source code to express some computations
as (potentially remote) service requests to a server controlled by the application programmer;
and there may be good reasons pertaining to local configuration and access rights
why the server's behavior may be known at link time, and its state shareable at runtime;
and thus the system can suitably optimize the implementation
and avoid the cost of runtime communication between physically isolated processes
(and later invalidate this optimization if the configuration changes).
Conversely, calls to well-defined functions can sometimes be usefully implemented
as requests to some server,
for instance one running on or managing a separate device
that is specialized for the task, that it can perform cheaper or faster.
Thus, whether the source code for some part of an application is modular or monolithic
is wholly independent of whether the implementation will be modular or monolithic at runtime.
The former is a matter of division of labor and specialization of tasks
between programmers at coding-time;
the latter is a matter of division of labor and specialization of tasks
between programs at runtime.

Controlling these communication channels happens at the meta-level.
So, external meta-level on simple programs (To a point: Unix shells).
Or, extend the program to have meta-level control language for the base functionality.
Houyhnhnms instead understand the need for system support for the meta-level at runtime.

Implicit channels:
Humans have irreflective languages with static binding of meaning to labels;
bindings are not directly express in the language;
instead programmers must explicitly manage handles
and manually follow a protocol consisting of calls to kernel APIs.
Houyhnhnms have reflective languages that can dynamically bind meaning to labels;
programmers can express the binding and rebinding of implicit communication channels
as regular language idioms whereby the compiler manages

the dynamic binding of implicit communication channels
to actual other programs on the other side.

that can't express the dynamic binding


He explained that at least for self-contained end-user applications,
the situation was very similar, at least superficially:

If self-contained applications that don't involve communicating data



### Different Shapes ###

Because of this high barrier in communication between components,
Human applications grow into big hulking pieces of software that each try to do everything,
yet can't.
These applications are each stretched into doing many of the same things, all of them badly.

and some things are just too far out there.

Failure of division of labour.
Failure of specialization of tasks.


### Extensibility through Reflection ###




While there are a lot of autistic applications,
most applications involve some communication with other applications.
And that's the difference between Houyhnhnm and Human applications becomes obvious:
Human applications are monolithic and irreflective,
whereas Houyhnhnm applications are modular and reflective.

In a Human application, any case of communication whatsoever
must be supported by an explicitly written case in a procedure;
which requires the programmer to foresee that case of communication and support it.
This is very work intensive, and any new case requires an update
to each and every application involved.
A copy/paste protocol can often alleviate the combinatorial explosion of cases
in communication between pairs of applications:
users may then select and cut or copy some data from one application, and paste it into another.

However, this only works where each application's programmer explicitly enabled
the proper half of the protocol (copying, or pasting).
And even then, it requires user-intensive interactions
and is not suitable to automation.
Some Human computer systems support some form of Object Linking and Embedding,
whereby some of this copy and pasting effort can be automated;
but it remains an advanced feature that requires yet more programmer support,
is only usable by experts, and remains brittle
when communication happens without human supervision.

Human computer systems do their worst to erase any meta-level at runtime,
and can only deal with a fixed number of hardwired cases;
these cases become ever more numerous and complex as the applications get larger,
yet they are never sufficient.
Eventually, some slightly more "clever" Human reinvents an extensible general case,
using a protocol that badly reimplements a small _ad hoc_ subset of dynamic typing and reflection.
Thereupon, whatever static types are used in these Human computer systems
become a burden that have to be fought constantly to keep the system extensible,
deconstructing and reconstructing them
at the interface between the system and its extensibility layer.

By contrast, Houyhnhnms embrace the fact that communication between applications
is an operation at the meta-level with respect to these applications:
at heart, it is about generating the code for two applications to communicate with each other.
This code may be very simple, but will crucially depend on the two applications.
Houyhnhnm computing systems can access the meta-level at runtime and simply generate that code
based on a declarative approach,
whereby each application suitably registers its interfaces and their types.
The type-driven code generation is simultaneously simple, general, safe and fast;
programmers have almost nothing to write by hand.

Types are thus a boon and helps generate all or most of the code
without the programmers having to write anything by hand.
Not having all the general-purpose code at the base-level
also makes it much easier to reason about safety property of the code base.
Not having to reinvent the wheel badly in every application
means that it types and reflection can be invented well
once (or a handful of times) in the entire system.


### Modularity through Declarativeness ###

This communication often happens from outside the application itself:
some application exposes some data, and
the user latter copies and pastes that data into another application.
Often, the might like the data to be directly linked from one application to the next,
and the entire copy/pasting automated;
but in Human computer systems, architectural limitations often make such automated linking
either altogether possible, or too brittle to happen without human supervision.

Extensibility.
Plug-ins.
XXXX

Delivering software as components, not applications (Human closest: browser plugins)

AOP: Modularity in implementation strategies
Aspects: search.



### Application Sandboxing ###

In Houyhnhnm computing systems, proper sandboxing ensures that
applications may only share or access data
according to the rules they have declared and that the system owner agreed to.
In particular, applications purporting to be autistic (as above)
are ensured to actually be autistic.
Proper sandboxing also means that the system owner isn't afraid of getting
viruses, malware or data leaks via an application.

Unlike Human computer systems, Houyhnhnm computing systems always
run all code in a fully abstract sandbox.
There is no way for code to distinguish between "normal" and "virtualized" machines.
If the system owner refuses to grant an application
access rights to some or all requested resources,
the application has no direct way to determine that
the access was denied;
instead, whenever it will access the resource,
it will get blank data, or fake data from a randomized honeypot,
or network delay notification, or whatever the system owner configured;
if the application is well-behaved, many unauthorized accesses may be optimized away;
but even if it's not, it has no way of telling that whether it's running "for real",
and is connected to some actual resource.

Allowing code to make the difference would be a huge security failure;
and any time a monitor in a production system
recognizes the attempt by a process to probe its environment
or otherwise break the abstraction, a serious security violation is flagged;
upon detection thereof, the process and its all associated processes are terminated,
up to the next suitably secure meta-level;
also the incident is logged, a police investigation is triggered,
and the responsible software vendor is arrested.
— Unless of course, the people responsible for the break in attempt
are the system's owners themselves, or penetration testers they have hired
to assess and improve their security, which is a recommended practice
among anyone hosting computations controlling any serious actual resources.

Note that proper sandboxing at heart has
[nothing whatsoever](/blog/2015/11/28/chapter-6-kernel-is-as-kernel-does)
to do with having "kernel" support for "containers"
or hardware-accelerated "virtual machines";
rather it is all about providing _full abstraction_,
i.e. abstractions that don't leak.
For instance, a user-interface should makes it impossible to do break the abstraction
without intentionally going to the meta-level.
you shouldn't be able to accidentally copy and paste
potentially sensitive information from one sandbox to the next;
instead, copy and pasting from one sandbox to another
should require extra confirmation _before_ any information is transfered;
the prompt is managed by a common meta-level between the sandboxes,
and provides the user with context about which are the sandboxes
and what is the considered content;
that the user may thus usefully confirm based on useful information
— or he may mark this context or a larger context as authorized
for copying and pasting without further confirmations.







### Sentient-Computer interface

Failure of UX Design of the programmer experience.



Not only does that make Houyhnhnm systems much simpler,
it also guarantees forever interoperability of every single piece data with any future system,
at whichever level of abstraction that data was defined.
If you want your data to remain relevant to your future self, or to be usable by other people, etc.,
you still need to wisely choose suitable algebraic data types,
to organize software into components with clean interfaces,
to pick appropriate policies that lead to suitably performant implementations,
to rely on suitable libraries.



Implementation vs expression.
expression can be implemented at the meta-level —
but that requires explicitly distinguishing the meta-level.
Human computer systems tend to either not allow meta-level programming,
or to conflate and confuse meta-levels.
Korzybsky: Insanity.
Confusing the thing and its representation.
Turing: universal languages wrt implementation, that can implement anything.
But unless the meta-level is universal, you cannot express everything.
And unless you actually implement other languages (DSLs),
then _in practice_, the restricted subset of your language that you actually use
is _not Turing-equivalent_.
